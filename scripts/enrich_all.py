#!/usr/bin/env python3
"""
ÐœÐ°ÑÑÐ¾Ð²Ð¾Ðµ Ð¾Ð±Ð¾Ð³Ð°Ñ‰ÐµÐ½Ð¸Ðµ ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¹:
1. Lead scoring (rule-based) Ð´Ð»Ñ Ð’Ð¡Ð•Ð¥ ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¹
2. Web crawling ÑÐ°Ð¹Ñ‚Ð¾Ð² â†’ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ ÐºÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ð¾Ð² (email, phone, socials)
3. Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ ÐºÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ð¾Ð² Ð² Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñƒ contacts

Ð—Ð°Ð¿ÑƒÑÐº: python scripts/enrich_all.py
"""
import os
import sys
import time

# Ensure project root is importable
ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
sys.path.insert(0, ROOT)

from sqlalchemy.orm import Session
from src.database import engine
from src.database.models import Base, Company, Contact
from src.ai.brain import calculate_lead_score
from src.recon.web_crawler import crawl_website

# Create tables if needed
Base.metadata.create_all(engine)


def enrich_lead_scores(session: Session):
    """Phase 1: Calculate lead score for all companies."""
    companies = session.query(Company).filter(
        Company.enrichment_status.in_(["new", None, ""])
    ).order_by(Company.revenue_total.desc().nulls_last()).all()

    print(f"\n{'='*60}")
    print(f"Ð¤ÐÐ—Ð 1: Lead Scoring â€” {len(companies)} ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¹")
    print(f"{'='*60}")

    scored = 0
    for c in companies:
        company_dict = {
            "name": c.name,
            "revenue_total": c.revenue_total,
            "sales_total": c.sales_total,
            "wb_present": c.wb_present,
            "ozon_present": c.ozon_present,
            "avg_price": c.avg_price,
            "website": c.website,
        }
        score = calculate_lead_score(company_dict)
        c.lead_score = score
        c.enrichment_status = "scored"
        scored += 1

        if scored % 100 == 0:
            print(f"  ...scored {scored}/{len(companies)}")
            session.commit()

    session.commit()
    print(f"âœ… Lead scoring Ð·Ð°Ð²ÐµÑ€ÑˆÑ‘Ð½: {scored} ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð¾")

    # Show top 10
    top = session.query(Company).order_by(Company.lead_score.desc()).limit(10).all()
    print(f"\nðŸ† Ð¢ÐžÐŸ-10 Ð¿Ð¾ lead score:")
    for i, c in enumerate(top, 1):
        print(f"  {i:2d}. [{c.lead_score:3d}] {c.name} â€” Ð²Ñ‹Ñ€ÑƒÑ‡ÐºÐ°: {c.revenue_total or 0:,.0f}")


def enrich_web_crawl(session: Session, limit: int = 100):
    """Phase 2: Crawl websites for contact info."""
    # Get companies with websites that haven't been crawled yet
    companies = session.query(Company).filter(
        Company.website.isnot(None),
        Company.website != "",
        Company.enrichment_status.in_(["scored", "new", None])
    ).order_by(Company.lead_score.desc().nulls_last()).limit(limit).all()

    print(f"\n{'='*60}")
    print(f"Ð¤ÐÐ—Ð 2: Web Crawling â€” {len(companies)} ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¹ Ñ ÑÐ°Ð¹Ñ‚Ð°Ð¼Ð¸")
    print(f"{'='*60}")

    if not companies:
        # Check if there are websites at all
        total_with_site = session.query(Company).filter(
            Company.website.isnot(None), Company.website != ""
        ).count()
        print(f"  ÐšÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¹ Ñ ÑÐ°Ð¹Ñ‚Ð°Ð¼Ð¸ Ð² Ð‘Ð”: {total_with_site}")
        if total_with_site == 0:
            print("  âš ï¸  ÐÐ¸ Ñƒ Ð¾Ð´Ð½Ð¾Ð¹ ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¸ Ð½ÐµÑ‚ Ð¿Ð¾Ð»Ñ website Ð² Ð‘Ð”.")
            print("  Ð”Ð°Ð½Ð½Ñ‹Ðµ Website Ð±ÐµÑ€ÑƒÑ‚ÑÑ Ð¸Ð· ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸ 'Website' Ð² Excel Ñ„Ð°Ð¹Ð»Ðµ.")
        return

    crawled = 0
    contacts_found = 0
    errors = 0

    for c in companies:
        url = c.website.strip()
        if not url:
            continue

        print(f"\n  [{crawled+1}/{len(companies)}] {c.name}: {url}")

        try:
            result = crawl_website(url, max_depth=2, max_pages=10)
            data = result.to_dict()

            # Save contacts
            for email in data.get("emails", []):
                existing = session.query(Contact).filter_by(
                    company_id=c.id, type="email", value=email
                ).first()
                if not existing:
                    session.add(Contact(
                        company_id=c.id, type="email", value=email,
                        source="web_crawl", label="Ð¡ ÑÐ°Ð¹Ñ‚Ð°"
                    ))
                    contacts_found += 1

            for phone in data.get("phones", []):
                existing = session.query(Contact).filter_by(
                    company_id=c.id, type="phone", value=phone
                ).first()
                if not existing:
                    session.add(Contact(
                        company_id=c.id, type="phone", value=phone,
                        source="web_crawl", label="Ð¡ ÑÐ°Ð¹Ñ‚Ð°"
                    ))
                    contacts_found += 1

            for platform, link in data.get("social_links", {}).items():
                existing = session.query(Contact).filter_by(
                    company_id=c.id, type=platform, value=link
                ).first()
                if not existing:
                    session.add(Contact(
                        company_id=c.id, type=platform, value=link,
                        source="web_crawl"
                    ))
                    contacts_found += 1

            # Update INN if found
            if data.get("inn") and not c.inn:
                c.inn = data["inn"]

            c.enrichment_status = "enriched"
            crawled += 1

            emails_str = ", ".join(data.get("emails", [])[:3]) or "â€”"
            phones_str = ", ".join(data.get("phones", [])[:2]) or "â€”"
            socials_str = ", ".join(data.get("social_links", {}).keys()) or "â€”"
            print(f"    ðŸ“§ {emails_str}")
            print(f"    ðŸ“ž {phones_str}")
            print(f"    ðŸ”— {socials_str}")

            session.commit()

        except Exception as e:
            print(f"    âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: {e}")
            errors += 1
            c.enrichment_status = "failed"
            session.commit()

    print(f"\n{'='*60}")
    print(f"âœ… Crawling Ð·Ð°Ð²ÐµÑ€ÑˆÑ‘Ð½:")
    print(f"   ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð¾: {crawled}")
    print(f"   ÐšÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ð¾Ð² Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾: {contacts_found}")
    print(f"   ÐžÑˆÐ¸Ð±Ð¾Ðº: {errors}")


def print_summary(session: Session):
    """Print final enrichment summary."""
    total = session.query(Company).count()
    scored = session.query(Company).filter(Company.lead_score > 0).count()
    enriched = session.query(Company).filter_by(enrichment_status="enriched").count()
    with_website = session.query(Company).filter(
        Company.website.isnot(None), Company.website != ""
    ).count()
    total_contacts = session.query(Contact).count()

    print(f"\n{'='*60}")
    print(f"ðŸ“Š Ð˜Ð¢ÐžÐ“Ðž:")
    print(f"   ÐšÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¹ Ð² Ð‘Ð”: {total}")
    print(f"   Ð¡ lead score > 0: {scored}")
    print(f"   Ð¡ ÑÐ°Ð¹Ñ‚Ð¾Ð¼: {with_website}")
    print(f"   ÐžÐ±Ð¾Ð³Ð°Ñ‰ÐµÐ½Ð¾ (crawled): {enriched}")
    print(f"   ÐšÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ð¾Ð² Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾: {total_contacts}")
    print(f"{'='*60}")

    # Score distribution
    from sqlalchemy import func
    segments = [
        ("ðŸ”´ Ð¥Ð¾Ð»Ð¾Ð´Ð½Ñ‹Ðµ (0-30)", 0, 30),
        ("ðŸŸ¡ Ð¢Ñ‘Ð¿Ð»Ñ‹Ðµ (31-60)", 31, 60),
        ("ðŸŸ¢ Ð“Ð¾Ñ€ÑÑ‡Ð¸Ðµ (61-80)", 61, 80),
        ("ðŸ”¥ Ð¢Ð¾Ð¿ (81-100)", 81, 100),
    ]
    print(f"\nðŸ“ˆ Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð¿Ð¾ lead score:")
    for label, lo, hi in segments:
        cnt = session.query(Company).filter(
            Company.lead_score >= lo, Company.lead_score <= hi
        ).count()
        print(f"   {label}: {cnt}")


if __name__ == "__main__":
    session = Session(engine)

    try:
        # Phase 1: Score all companies
        enrich_lead_scores(session)

        # Phase 2: Crawl websites
        enrich_web_crawl(session, limit=50)  # Start with top 50 by score

        # Summary
        print_summary(session)

    finally:
        session.close()
